{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 10, 6, 10, 6, 1]' is invalid for input of size 4096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparam\u001b[39;00m \u001b[39mimport\u001b[39;00m param_check, seed_everything\n\u001b[1;32m     20\u001b[0m model_list \u001b[39m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m             \u001b[39m#     'DnCNN', 'ResNet18', \u001b[39;00m\n\u001b[1;32m     22\u001b[0m             \u001b[39m# #   'ResNet34', 'ResNet50', 'ResNet101','ResNet152', \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[39m# 'pix2pix',\u001b[39;00m\n\u001b[1;32m     26\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mSwinIR128\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSwinIR64\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSwinIR32\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m models \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mDnCNN\u001b[39m\u001b[39m'\u001b[39m: DnCNN\u001b[39m.\u001b[39mDnCNN(), \n\u001b[1;32m     28\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNet18\u001b[39m\u001b[39m'\u001b[39m: ResNet\u001b[39m.\u001b[39mResNet18(), \n\u001b[1;32m     29\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNet34\u001b[39m\u001b[39m'\u001b[39m: ResNet\u001b[39m.\u001b[39mResNet34(), \n\u001b[1;32m     30\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNet50\u001b[39m\u001b[39m'\u001b[39m: ResNet\u001b[39m.\u001b[39mResNet50(), \n\u001b[1;32m     31\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNet101\u001b[39m\u001b[39m'\u001b[39m: ResNet\u001b[39m.\u001b[39mResNet101(), \n\u001b[1;32m     32\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNet152\u001b[39m\u001b[39m'\u001b[39m: ResNet\u001b[39m.\u001b[39mResNet152(), \n\u001b[1;32m     33\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mRFDN\u001b[39m\u001b[39m'\u001b[39m: RFDN\u001b[39m.\u001b[39mRFDN(),\n\u001b[1;32m     34\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mResNetED\u001b[39m\u001b[39m'\u001b[39m : ResNetED\u001b[39m.\u001b[39mResNet18(),\n\u001b[1;32m     35\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mDRLN\u001b[39m\u001b[39m'\u001b[39m : DRLN\u001b[39m.\u001b[39mDRLN(),\n\u001b[1;32m     36\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mSwinIR128\u001b[39m\u001b[39m'\u001b[39m : net(upscale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, in_chans\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, img_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, window_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \\\n\u001b[1;32m     37\u001b[0m                     img_range\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, depths\u001b[39m=\u001b[39m[\u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m], embed_dim\u001b[39m=\u001b[39m\u001b[39m180\u001b[39m, num_heads\u001b[39m=\u001b[39m[\u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m], \\\n\u001b[1;32m     38\u001b[0m                     mlp_ratio\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, upsampler\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, resi_connection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1conv\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m---> 39\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mSwinIR64\u001b[39m\u001b[39m'\u001b[39m : net(upscale\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, in_chans\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, img_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, window_size\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, \\\n\u001b[1;32m     40\u001b[0m                     img_range\u001b[39m=\u001b[39;49m\u001b[39m1.\u001b[39;49m, depths\u001b[39m=\u001b[39;49m[\u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m], embed_dim\u001b[39m=\u001b[39;49m\u001b[39m180\u001b[39;49m, num_heads\u001b[39m=\u001b[39;49m[\u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m6\u001b[39;49m], \\\n\u001b[1;32m     41\u001b[0m                     mlp_ratio\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, upsampler\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, resi_connection\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m1conv\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     42\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mSwinIR32\u001b[39m\u001b[39m'\u001b[39m : net(upscale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, in_chans\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, img_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, window_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \\\n\u001b[1;32m     43\u001b[0m                     img_range\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, depths\u001b[39m=\u001b[39m[\u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m], embed_dim\u001b[39m=\u001b[39m\u001b[39m180\u001b[39m, num_heads\u001b[39m=\u001b[39m[\u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m], \\\n\u001b[1;32m     44\u001b[0m                     mlp_ratio\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, upsampler\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, resi_connection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1conv\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     45\u001b[0m             \n\u001b[1;32m     46\u001b[0m           }\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparam_print\u001b[39m(model):\n\u001b[1;32m     49\u001b[0m     param_check(model)\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:816\u001b[0m, in \u001b[0;36mSwinIR.__init__\u001b[0;34m(self, img_size, patch_size, in_chans, embed_dim, depths, num_heads, window_size, mlp_ratio, qkv_bias, qk_scale, drop_rate, attn_drop_rate, drop_path_rate, norm_layer, ape, patch_norm, use_checkpoint, upscale, img_range, upsampler, resi_connection, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList()\n\u001b[1;32m    815\u001b[0m \u001b[39mfor\u001b[39;00m i_layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m--> 816\u001b[0m     layer \u001b[39m=\u001b[39m RSTB(dim\u001b[39m=\u001b[39;49membed_dim,\n\u001b[1;32m    817\u001b[0m                  input_resolution\u001b[39m=\u001b[39;49m(patches_resolution[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    818\u001b[0m                                    patches_resolution[\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m    819\u001b[0m                  depth\u001b[39m=\u001b[39;49mdepths[i_layer],\n\u001b[1;32m    820\u001b[0m                  num_heads\u001b[39m=\u001b[39;49mnum_heads[i_layer],\n\u001b[1;32m    821\u001b[0m                  window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    822\u001b[0m                  mlp_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp_ratio,\n\u001b[1;32m    823\u001b[0m                  qkv_bias\u001b[39m=\u001b[39;49mqkv_bias, qk_scale\u001b[39m=\u001b[39;49mqk_scale,\n\u001b[1;32m    824\u001b[0m                  drop\u001b[39m=\u001b[39;49mdrop_rate, attn_drop\u001b[39m=\u001b[39;49mattn_drop_rate,\n\u001b[1;32m    825\u001b[0m                  drop_path\u001b[39m=\u001b[39;49mdpr[\u001b[39msum\u001b[39;49m(depths[:i_layer]):\u001b[39msum\u001b[39;49m(depths[:i_layer \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m])],  \u001b[39m# no impact on SR results\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m                  norm_layer\u001b[39m=\u001b[39;49mnorm_layer,\n\u001b[1;32m    827\u001b[0m                  downsample\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    828\u001b[0m                  use_checkpoint\u001b[39m=\u001b[39;49muse_checkpoint,\n\u001b[1;32m    829\u001b[0m                  img_size\u001b[39m=\u001b[39;49mimg_size,\n\u001b[1;32m    830\u001b[0m                  patch_size\u001b[39m=\u001b[39;49mpatch_size,\n\u001b[1;32m    831\u001b[0m                  resi_connection\u001b[39m=\u001b[39;49mresi_connection\n\u001b[1;32m    832\u001b[0m \n\u001b[1;32m    833\u001b[0m                  )\n\u001b[1;32m    834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mappend(layer)\n\u001b[1;32m    835\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m=\u001b[39m norm_layer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features)\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:561\u001b[0m, in \u001b[0;36mRSTB.__init__\u001b[0;34m(self, dim, input_resolution, depth, num_heads, window_size, mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path, norm_layer, downsample, use_checkpoint, img_size, patch_size, resi_connection)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim \u001b[39m=\u001b[39m dim\n\u001b[1;32m    559\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_resolution \u001b[39m=\u001b[39m input_resolution\n\u001b[0;32m--> 561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_group \u001b[39m=\u001b[39m BasicLayer(dim\u001b[39m=\u001b[39;49mdim,\n\u001b[1;32m    562\u001b[0m                                  input_resolution\u001b[39m=\u001b[39;49minput_resolution,\n\u001b[1;32m    563\u001b[0m                                  depth\u001b[39m=\u001b[39;49mdepth,\n\u001b[1;32m    564\u001b[0m                                  num_heads\u001b[39m=\u001b[39;49mnum_heads,\n\u001b[1;32m    565\u001b[0m                                  window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    566\u001b[0m                                  mlp_ratio\u001b[39m=\u001b[39;49mmlp_ratio,\n\u001b[1;32m    567\u001b[0m                                  qkv_bias\u001b[39m=\u001b[39;49mqkv_bias, qk_scale\u001b[39m=\u001b[39;49mqk_scale,\n\u001b[1;32m    568\u001b[0m                                  drop\u001b[39m=\u001b[39;49mdrop, attn_drop\u001b[39m=\u001b[39;49mattn_drop,\n\u001b[1;32m    569\u001b[0m                                  drop_path\u001b[39m=\u001b[39;49mdrop_path,\n\u001b[1;32m    570\u001b[0m                                  norm_layer\u001b[39m=\u001b[39;49mnorm_layer,\n\u001b[1;32m    571\u001b[0m                                  downsample\u001b[39m=\u001b[39;49mdownsample,\n\u001b[1;32m    572\u001b[0m                                  use_checkpoint\u001b[39m=\u001b[39;49muse_checkpoint)\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m resi_connection \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1conv\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(dim, dim, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:490\u001b[0m, in \u001b[0;36mBasicLayer.__init__\u001b[0;34m(self, dim, input_resolution, depth, num_heads, window_size, mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path, norm_layer, downsample, use_checkpoint)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_checkpoint \u001b[39m=\u001b[39m use_checkpoint\n\u001b[1;32m    489\u001b[0m \u001b[39m# build blocks\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m    491\u001b[0m     SwinTransformerBlock(dim\u001b[39m=\u001b[39mdim, input_resolution\u001b[39m=\u001b[39minput_resolution,\n\u001b[1;32m    492\u001b[0m                          num_heads\u001b[39m=\u001b[39mnum_heads, window_size\u001b[39m=\u001b[39mwindow_size,\n\u001b[1;32m    493\u001b[0m                          shift_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39melse\u001b[39;00m window_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m    494\u001b[0m                          mlp_ratio\u001b[39m=\u001b[39mmlp_ratio,\n\u001b[1;32m    495\u001b[0m                          qkv_bias\u001b[39m=\u001b[39mqkv_bias, qk_scale\u001b[39m=\u001b[39mqk_scale,\n\u001b[1;32m    496\u001b[0m                          drop\u001b[39m=\u001b[39mdrop, attn_drop\u001b[39m=\u001b[39mattn_drop,\n\u001b[1;32m    497\u001b[0m                          drop_path\u001b[39m=\u001b[39mdrop_path[i] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(drop_path, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m drop_path,\n\u001b[1;32m    498\u001b[0m                          norm_layer\u001b[39m=\u001b[39mnorm_layer)\n\u001b[1;32m    499\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(depth)])\n\u001b[1;32m    501\u001b[0m \u001b[39m# patch merging layer\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m downsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:491\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_checkpoint \u001b[39m=\u001b[39m use_checkpoint\n\u001b[1;32m    489\u001b[0m \u001b[39m# build blocks\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[0;32m--> 491\u001b[0m     SwinTransformerBlock(dim\u001b[39m=\u001b[39;49mdim, input_resolution\u001b[39m=\u001b[39;49minput_resolution,\n\u001b[1;32m    492\u001b[0m                          num_heads\u001b[39m=\u001b[39;49mnum_heads, window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    493\u001b[0m                          shift_size\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m \u001b[39mif\u001b[39;49;00m (i \u001b[39m%\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39melse\u001b[39;49;00m window_size \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m    494\u001b[0m                          mlp_ratio\u001b[39m=\u001b[39;49mmlp_ratio,\n\u001b[1;32m    495\u001b[0m                          qkv_bias\u001b[39m=\u001b[39;49mqkv_bias, qk_scale\u001b[39m=\u001b[39;49mqk_scale,\n\u001b[1;32m    496\u001b[0m                          drop\u001b[39m=\u001b[39;49mdrop, attn_drop\u001b[39m=\u001b[39;49mattn_drop,\n\u001b[1;32m    497\u001b[0m                          drop_path\u001b[39m=\u001b[39;49mdrop_path[i] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(drop_path, \u001b[39mlist\u001b[39;49m) \u001b[39melse\u001b[39;49;00m drop_path,\n\u001b[1;32m    498\u001b[0m                          norm_layer\u001b[39m=\u001b[39;49mnorm_layer)\n\u001b[1;32m    499\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(depth)])\n\u001b[1;32m    501\u001b[0m \u001b[39m# patch merging layer\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m downsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:320\u001b[0m, in \u001b[0;36mSwinTransformerBlock.__init__\u001b[0;34m(self, dim, input_resolution, num_heads, window_size, shift_size, mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path, act_layer, norm_layer)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp \u001b[39m=\u001b[39m Mlp(in_features\u001b[39m=\u001b[39mdim, hidden_features\u001b[39m=\u001b[39mmlp_hidden_dim, act_layer\u001b[39m=\u001b[39mact_layer, drop\u001b[39m=\u001b[39mdrop)\n\u001b[1;32m    319\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshift_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 320\u001b[0m     attn_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_mask(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_resolution)\n\u001b[1;32m    321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     attn_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:342\u001b[0m, in \u001b[0;36mSwinTransformerBlock.calculate_mask\u001b[0;34m(self, x_size)\u001b[0m\n\u001b[1;32m    339\u001b[0m         img_mask[:, h, w, :] \u001b[39m=\u001b[39m cnt\n\u001b[1;32m    340\u001b[0m         cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 342\u001b[0m mask_windows \u001b[39m=\u001b[39m window_partition(img_mask, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow_size)  \u001b[39m# nW, window_size, window_size, 1\u001b[39;00m\n\u001b[1;32m    343\u001b[0m mask_windows \u001b[39m=\u001b[39m mask_windows\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)\n\u001b[1;32m    344\u001b[0m attn_mask \u001b[39m=\u001b[39m mask_windows\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m mask_windows\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/mlp_compitition/cjh/models/models/network_swinir.py:153\u001b[0m, in \u001b[0;36mwindow_partition\u001b[0;34m(x, window_size)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m    x: (B, H, W, C)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m    windows: (num_windows*B, window_size, window_size, C)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m B, H, W, C \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 153\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mview(B, H \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m window_size, window_size, W \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m window_size, window_size, C)\n\u001b[1;32m    154\u001b[0m windows \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, window_size, window_size, C)\n\u001b[1;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m windows\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 10, 6, 10, 6, 1]' is invalid for input of size 4096"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import argparse\n",
    "import models.DnCNN as DnCNN, models.ResNet as ResNet, models.RFDN as RFDN, models.ResNet_ED as ResNetED, models.DRLN as DRLN, models.pix2pix as pix2pix\n",
    "from models.network_swinir import SwinIR as net\n",
    "from utils.param import param_check, seed_everything\n",
    "\n",
    "model_list = [\n",
    "            #     'DnCNN', 'ResNet18', \n",
    "            # #   'ResNet34', 'ResNet50', 'ResNet101','ResNet152', \n",
    "            #   'RFDN', 'ResNetED', \n",
    "            # 'DRLN', \n",
    "            # 'pix2pix',\n",
    "            'SwinIR128', 'SwinIR64','SwinIR32']\n",
    "models = {'DnCNN': DnCNN.DnCNN(), \n",
    "          'ResNet18': ResNet.ResNet18(), \n",
    "          'ResNet34': ResNet.ResNet34(), \n",
    "          'ResNet50': ResNet.ResNet50(), \n",
    "          'ResNet101': ResNet.ResNet101(), \n",
    "          'ResNet152': ResNet.ResNet152(), \n",
    "          'RFDN': RFDN.RFDN(),\n",
    "          'ResNetED' : ResNetED.ResNet18(),\n",
    "          'DRLN' : DRLN.DRLN(),\n",
    "          'SwinIR128' : net(upscale=1, in_chans=3, img_size=128, window_size=8, \\\n",
    "                    img_range=1., depths=[6, 6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6], \\\n",
    "                    mlp_ratio=2, upsampler='', resi_connection='1conv'),\n",
    "          'SwinIR64' : net(upscale=1, in_chans=3, img_size=64, window_size=8, \\\n",
    "                    img_range=1., depths=[6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6], \\\n",
    "                    mlp_ratio=2, upsampler='', resi_connection='1conv'),\n",
    "          'SwinIR32' : net(upscale=1, in_chans=3, img_size=32, window_size=8, \\\n",
    "                    img_range=1., depths=[6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6], \\\n",
    "                    mlp_ratio=2, upsampler='', resi_connection='1conv'),\n",
    "            \n",
    "          }\n",
    "\n",
    "def param_print(model):\n",
    "    param_check(model)\n",
    "    param_check(model, True)\n",
    "    print(summary(model, (3, 128, 128)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "for m in model_list:   \n",
    "    print('\\n\\n',m,' 모델은 다음과 같다.')\n",
    "    if m == 'pix2pix':\n",
    "        G = pix2pix.Generator()\n",
    "        D = pix2pix.Discriminator()\n",
    "        print('총 : ',param_check(G) + param_check(D))\n",
    "        print('총 : ',param_check(G, True) + param_check(D, True))\n",
    "        print(summary(G, (3, 256, 256)))\n",
    "        print(summary(D, (6, 256, 256)))\n",
    "    else:\n",
    "        # param_print(models[m])\n",
    "        param_check(models[m])\n",
    "        param_check(models[m], True)\n",
    "        # print(summary(models[m], (3, 128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
